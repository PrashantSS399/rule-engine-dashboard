{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "692b1f31-b709-4e3a-98e5-04d3a09b33aa",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f800f006-6e2a-402b-97bd-a3a7cf40623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Union, Optional, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7b524-e625-4b9c-8da1-866792566e80",
   "metadata": {},
   "source": [
    "# Importing DataBase From PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "48edb548-ebb0-4d2b-a368-9e56398b33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_engine():\n",
    "    \"\"\"Create and return a database engine\"\"\"\n",
    "    return create_engine(\"postgresql+psycopg2://postgres:password@localhost:5432/Data_Asset_Linkage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741587c3-a229-4fef-834b-3c2e5975c549",
   "metadata": {},
   "source": [
    "# LEVEL 0: Making Functions to fetch the data from the tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "71c68387-40cb-4dce-a4f7-9d2d727739d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Customer information Function \n",
    "def get_customers(\n",
    "    customer_id: Union[str, List[str], None] = None,\n",
    "    name: Union[str, List[str], None] = None,\n",
    "    city: Union[str, List[str], None] = None,\n",
    "    update_date: Union[str, datetime.date, List[Union[str, datetime.date]], None] = None,\n",
    "    exact_match: bool = True,\n",
    "    min_update_date: Union[str, datetime.date, None] = None,\n",
    "    max_update_date: Union[str, datetime.date, None] = None,\n",
    "    select_columns: Union[str, List[str], None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ultimate flexible customer data retrieval with support for all parameter types.\n",
    "    \n",
    "    Parameters:\n",
    "    - customer_id: Single ID or list of IDs (exact match)\n",
    "    - name: Single name or list of names (exact/partial match)\n",
    "    - city: Single city or list of cities (exact/partial match)\n",
    "    - update_date: Single date or list of dates (str 'YYYY-MM-DD' or date object)\n",
    "    - exact_match: False for partial text matching (default True)\n",
    "    - min_update_date: Minimum date filter (inclusive)\n",
    "    - max_update_date: Maximum date filter (inclusive)\n",
    "    - select_columns: Column name or list of column names to return\n",
    "    \n",
    "    Returns:\n",
    "    - Pandas DataFrame with matching customer records\n",
    "    \"\"\"\n",
    "    \n",
    "    #Handle column selection\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, list):\n",
    "            column_str = \", \".join(select_columns)\n",
    "        else:\n",
    "            column_str = select_columns\n",
    "    else:\n",
    "        column_str = \"*\"\n",
    "\n",
    "    # Base query\n",
    "    query = f\"SELECT {column_str} FROM customer WHERE 1=1\"\n",
    "    params = {}\n",
    "    param_counter = 0\n",
    "    \n",
    "    def add_condition(field, value, exact=True, is_date=False):\n",
    "        nonlocal query, params, param_counter\n",
    "        param_prefix = f\"{field}_{param_counter}\"\n",
    "        param_counter += 1\n",
    "        \n",
    "        if isinstance(value, (list, tuple)):\n",
    "            conditions = []\n",
    "            for i, val in enumerate(value):\n",
    "                param_name = f\"{param_prefix}_{i}\"\n",
    "                if is_date and isinstance(val, str):\n",
    "                    val = datetime.strptime(val, '%Y-%m-%d').date()\n",
    "                if exact:\n",
    "                    conditions.append(f\"{field} = %({param_name})s\")\n",
    "                else:\n",
    "                    conditions.append(f\"{field} ILIKE %({param_name})s\")\n",
    "                    val = f\"%{val}%\" if not is_date else val\n",
    "                params[param_name] = val\n",
    "            query += \" AND (\" + \" OR \".join(conditions) + \")\"\n",
    "        else:\n",
    "            if is_date and isinstance(value, str):\n",
    "                value = datetime.strptime(value, '%Y-%m-%d').date()\n",
    "            if exact:\n",
    "                query += f\" AND {field} = %({param_prefix})s\"\n",
    "            else:\n",
    "                query += f\" AND {field} ILIKE %({param_prefix})s\"\n",
    "                value = f\"%{value}%\" if not is_date else value\n",
    "            params[param_prefix] = value\n",
    "    \n",
    "    # Add filters\n",
    "    if customer_id is not None:\n",
    "        add_condition(\"customer_id\", customer_id, exact=True)\n",
    "    \n",
    "    if name is not None:\n",
    "        add_condition(\"name\", name, exact=exact_match)\n",
    "    \n",
    "    if city is not None:\n",
    "        add_condition(\"city\", city, exact=exact_match)\n",
    "    \n",
    "    if update_date is not None:\n",
    "        add_condition(\"update_date\", update_date, exact=True, is_date=True)\n",
    "    \n",
    "    # Date range filters\n",
    "    if min_update_date:\n",
    "        if isinstance(min_update_date, str):\n",
    "            min_update_date = datetime.strptime(min_update_date, '%Y-%m-%d').date()\n",
    "        params['min_date'] = min_update_date\n",
    "        query += \" AND update_date >= %(min_date)s\"\n",
    "    \n",
    "    if max_update_date:\n",
    "        if isinstance(max_update_date, str):\n",
    "            max_update_date = datetime.strptime(max_update_date, '%Y-%m-%d').date()\n",
    "        params['max_date'] = max_update_date\n",
    "        query += \" AND update_date <= %(max_date)s\"\n",
    "    \n",
    "    # Execute the query\n",
    "    engine = get_db_engine()\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            if params:\n",
    "                with conn.connection.cursor() as cursor:\n",
    "                    cursor.execute(query, params)\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    data = cursor.fetchall()\n",
    "                    return pd.DataFrame(data, columns=columns)\n",
    "            else:\n",
    "                return pd.read_sql(query, conn)\n",
    "    finally:\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1764d7f4-fab6-42fa-b861-073c13709864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Accounts information Function\n",
    "def get_accounts(\n",
    "    account_no: Union[str, List[str], None] = None,\n",
    "    account_type: Union[str, List[str], None] = None,\n",
    "    customer_id: Union[str, List[str], None] = None,\n",
    "    account_status: Union[str, List[str], None] = None,\n",
    "    activation_date: Union[str, datetime.date, List[Union[str, datetime.date]], None] = None,\n",
    "    exact_match: bool = True,\n",
    "    min_activation_date: Union[str, datetime.date, None] = None,\n",
    "    max_activation_date: Union[str, datetime.date, None] = None,\n",
    "    select_columns: Union[str, List[str], None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flexible account data retrieval with support for all parameter types.\n",
    "\n",
    "    Parameters:\n",
    "    - account_no: Single or list of account numbers\n",
    "    - account_type: Single or list of account types\n",
    "    - customer_id: Single or list of customer IDs\n",
    "    - account_status: Single or list of statuses\n",
    "    - activation_date: Single or list of activation dates\n",
    "    - exact_match: Use False for partial text matching\n",
    "    - min_activation_date: Inclusive minimum activation date\n",
    "    - max_activation_date: Inclusive maximum activation date\n",
    "    - select_columns: Optional list or string of specific columns to return\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with matching account records\n",
    "    \"\"\"\n",
    "\n",
    "    #Handle column selection\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, list):\n",
    "            column_str = \", \".join(select_columns)\n",
    "        else:\n",
    "            column_str = select_columns\n",
    "    else:\n",
    "        column_str = \"*\"\n",
    "\n",
    "    query = f\"SELECT {column_str} FROM accounts WHERE 1=1\"\n",
    "    params = {}\n",
    "    param_counter = 0\n",
    "\n",
    "    def add_condition(field, value, exact=True, is_date=False):\n",
    "        nonlocal query, params, param_counter\n",
    "        param_prefix = f\"{field}_{param_counter}\"\n",
    "        param_counter += 1\n",
    "\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            conditions = []\n",
    "            for i, val in enumerate(value):\n",
    "                param_name = f\"{param_prefix}_{i}\"\n",
    "                if is_date and isinstance(val, str):\n",
    "                    val = datetime.strptime(val, '%Y-%m-%d').date()\n",
    "                if exact:\n",
    "                    conditions.append(f\"{field} = %({param_name})s\")\n",
    "                else:\n",
    "                    conditions.append(f\"{field} ILIKE %({param_name})s\")\n",
    "                    val = f\"%{val}%\" if not is_date else val\n",
    "                params[param_name] = val\n",
    "            query += \" AND (\" + \" OR \".join(conditions) + \")\"\n",
    "        else:\n",
    "            if is_date and isinstance(value, str):\n",
    "                value = datetime.strptime(value, '%Y-%m-%d').date()\n",
    "            if exact:\n",
    "                query += f\" AND {field} = %({param_prefix})s\"\n",
    "            else:\n",
    "                query += f\" AND {field} ILIKE %({param_prefix})s\"\n",
    "                value = f\"%{value}%\" if not is_date else value\n",
    "            params[param_prefix] = value\n",
    "\n",
    "    # Apply filters\n",
    "    if account_no is not None:\n",
    "        add_condition(\"account_no\", account_no, exact=True)\n",
    "    if account_type is not None:\n",
    "        add_condition(\"account_type\", account_type, exact=exact_match)\n",
    "    if customer_id is not None:\n",
    "        add_condition(\"customer_id\", customer_id, exact=True)\n",
    "    if account_status is not None:\n",
    "        add_condition(\"account_status\", account_status, exact=exact_match)\n",
    "    if activation_date is not None:\n",
    "        add_condition(\"activation_date\", activation_date, exact=True, is_date=True)\n",
    "    if min_activation_date:\n",
    "        if isinstance(min_activation_date, str):\n",
    "            min_activation_date = datetime.strptime(min_activation_date, '%Y-%m-%d').date()\n",
    "        query += \" AND activation_date >= %(min_date)s\"\n",
    "        params['min_date'] = min_activation_date\n",
    "    if max_activation_date:\n",
    "        if isinstance(max_activation_date, str):\n",
    "            max_activation_date = datetime.strptime(max_activation_date, '%Y-%m-%d').date()\n",
    "        query += \" AND activation_date <= %(max_date)s\"\n",
    "        params['max_date'] = max_activation_date\n",
    "\n",
    "    # Execute the query\n",
    "    engine = get_db_engine()\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            if params:\n",
    "                with conn.connection.cursor() as cursor:\n",
    "                    cursor.execute(query, params)\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    data = cursor.fetchall()\n",
    "                    return pd.DataFrame(data, columns=columns)\n",
    "            else:\n",
    "                return pd.read_sql(query, conn)\n",
    "    finally:\n",
    "        engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab83a3ac-6d81-47d6-af56-0d03cfeb1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Transaction information Function\n",
    "def get_transactions(\n",
    "    transaction_id: Union[int, List[int], None] = None,\n",
    "    account_no: Union[str, List[str], None] = None,\n",
    "    customer_id: Union[str, List[str], None] = None,\n",
    "    amount: Union[float, List[float], None] = None,\n",
    "    min_amount: float = None,\n",
    "    max_amount: float = None,\n",
    "    transaction_time: Union[str, datetime, List[Union[str, datetime]], None] = None,\n",
    "    min_transaction_time: Union[str, datetime, None] = None,\n",
    "    max_transaction_time: Union[str, datetime, None] = None,\n",
    "    select_columns: Union[str, List[str], None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flexible transaction data retrieval with filters on all key fields.\n",
    "\n",
    "    Parameters:\n",
    "    - transaction_id: single ID or list\n",
    "    - account_no: single or list of account numbers\n",
    "    - customer_id: single or list of customer IDs\n",
    "    - amount: exact amount or list of exact amounts\n",
    "    - min_amount: lower bound for amount\n",
    "    - max_amount: upper bound for amount\n",
    "    - transaction_time: exact timestamp or list of timestamps\n",
    "    - min_transaction_time: datetime lower bound\n",
    "    - max_transaction_time: datetime upper bound\n",
    "    - select_columns: List or comma-separated string of columns to return\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with matching transactions\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle selected columns\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, list):\n",
    "            column_str = \", \".join(select_columns)\n",
    "        else:\n",
    "            column_str = select_columns\n",
    "    else:\n",
    "        column_str = \"*\"\n",
    "\n",
    "    query = f\"SELECT {column_str} FROM transactions WHERE 1=1\"\n",
    "    params = {}\n",
    "    param_counter = 0\n",
    "\n",
    "    def add_condition(field, value, is_date=False):\n",
    "        nonlocal query, params, param_counter\n",
    "        param_prefix = f\"{field}_{param_counter}\"\n",
    "        param_counter += 1\n",
    "\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            conditions = []\n",
    "            for i, val in enumerate(value):\n",
    "                param_name = f\"{param_prefix}_{i}\"\n",
    "                if is_date and isinstance(val, str):\n",
    "                    val = datetime.strptime(val, '%Y-%m-%d %H:%M:%S')\n",
    "                conditions.append(f\"{field} = %({param_name})s\")\n",
    "                params[param_name] = val\n",
    "            query += \" AND (\" + \" OR \".join(conditions) + \")\"\n",
    "        else:\n",
    "            if is_date and isinstance(value, str):\n",
    "                value = datetime.strptime(value, '%Y-%m-%d %H:%M:%S')\n",
    "            query += f\" AND {field} = %({param_prefix})s\"\n",
    "            params[param_prefix] = value\n",
    "\n",
    "    # Apply filters\n",
    "    if transaction_id is not None:\n",
    "        add_condition(\"transaction_id\", transaction_id)\n",
    "    if account_no is not None:\n",
    "        add_condition(\"account_no\", account_no)\n",
    "    if customer_id is not None:\n",
    "        add_condition(\"customer_id\", customer_id)\n",
    "    if amount is not None:\n",
    "        add_condition(\"amount\", amount)\n",
    "    if min_amount is not None:\n",
    "        query += \" AND amount >= %(min_amount)s\"\n",
    "        params['min_amount'] = min_amount\n",
    "    if max_amount is not None:\n",
    "        query += \" AND amount <= %(max_amount)s\"\n",
    "        params['max_amount'] = max_amount\n",
    "    if transaction_time is not None:\n",
    "        add_condition(\"transaction_time\", transaction_time, is_date=True)\n",
    "    if min_transaction_time:\n",
    "        if isinstance(min_transaction_time, str):\n",
    "            min_transaction_time = datetime.strptime(min_transaction_time, '%Y-%m-%d %H:%M:%S')\n",
    "        query += \" AND transaction_time >= %(min_time)s\"\n",
    "        params['min_time'] = min_transaction_time\n",
    "    if max_transaction_time:\n",
    "        if isinstance(max_transaction_time, str):\n",
    "            max_transaction_time = datetime.strptime(max_transaction_time, '%Y-%m-%d %H:%M:%S')\n",
    "        query += \" AND transaction_time <= %(max_time)s\"\n",
    "        params['max_time'] = max_transaction_time\n",
    "\n",
    "    # Execute query\n",
    "    engine = get_db_engine()\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            if params:\n",
    "                with conn.connection.cursor() as cursor:\n",
    "                    cursor.execute(query, params)\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    data = cursor.fetchall()\n",
    "                    return pd.DataFrame(data, columns=columns)\n",
    "            else:\n",
    "                return pd.read_sql(query, conn)\n",
    "    finally:\n",
    "        engine.dispose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f92dca-dd97-468c-8b43-7707e0487952",
   "metadata": {},
   "source": [
    "# LEVEL 1: Merging/Joining The Tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "670c9c25-913f-45c2-8679-3f5b6143e68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_join_cust_acc(\n",
    "    join_type: str = \"left\",\n",
    "    customer_on: Union[str, List[str]] = \"customer_id\",\n",
    "    account_on: Union[str, List[str]] = \"customer_id\",\n",
    "    customer_filters: Optional[dict] = None,\n",
    "    account_filters: Optional[dict] = None,\n",
    "    cust: Optional[pd.DataFrame] = None,\n",
    "    acc: Optional[pd.DataFrame] = None,\n",
    "    select_columns: Union[List[str], str, None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins customer and account data on specified keys.\n",
    "\n",
    "    Parameters:\n",
    "    - join_type (str): Type of join (e.g., 'left', 'inner'). Default is 'left'.\n",
    "    - customer_on (str or List[str]): Column(s) in customer data to join on.\n",
    "    - account_on (str or List[str]): Column(s) in account data to join on.\n",
    "    - customer_filters (dict): Filters to apply if cust DataFrame is not provided.\n",
    "    - account_filters (dict): Filters to apply if acc DataFrame is not provided.\n",
    "    - cust (pd.DataFrame): Optional. If provided, used directly as customers data.\n",
    "    - acc (pd.DataFrame): Optional. If provided, used directly as accounts data.\n",
    "    - select_columns (str or List[str]): Columns to keep in final DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Merged DataFrame based on join configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use provided DataFrames or fetch with filters\n",
    "    customers_df = cust if cust is not None else get_customers(**(customer_filters or {}))\n",
    "    accounts_df = acc if acc is not None else get_accounts(**(account_filters or {}))\n",
    "\n",
    "    # Normalize join keys\n",
    "    customer_keys = [customer_on] if isinstance(customer_on, str) else customer_on\n",
    "    account_keys = [account_on] if isinstance(account_on, str) else account_on\n",
    "\n",
    "    # Perform join\n",
    "    merged = pd.merge(\n",
    "        customers_df,\n",
    "        accounts_df,\n",
    "        how=join_type.lower(),\n",
    "        left_on=customer_keys,\n",
    "        right_on=account_keys,\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "\n",
    "    # Drop duplicate join cols\n",
    "    for ak in account_keys:\n",
    "        dup_col = f\"{ak}_dup\"\n",
    "        if dup_col in merged.columns:\n",
    "            merged.drop(columns=[dup_col], inplace=True)\n",
    "\n",
    "    # Select specific columns if provided\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, str):\n",
    "            select_columns = [select_columns]\n",
    "        merged = merged[select_columns]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6c296df2-c941-4961-ab40-f88a3b6be8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_join_cust_tran(\n",
    "    join_type: str = \"left\",\n",
    "    customer_on: Union[str, List[str]] = \"customer_id\",\n",
    "    transaction_on: Union[str, List[str]] = \"customer_id\",\n",
    "    customer_filters: Optional[dict] = None,\n",
    "    transaction_filters: Optional[dict] = None,\n",
    "    cust: Optional[pd.DataFrame] = None,\n",
    "    tran: Optional[pd.DataFrame] = None,\n",
    "    select_columns: Union[List[str], str, None] = None  #\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins customer and transaction data on specified keys.\n",
    "\n",
    "    Parameters:\n",
    "    - join_type (str): Type of SQL join ('left', 'inner', etc.). Default is 'left'.\n",
    "    - customer_on (str or List[str]): Key(s) from the customer table to join on.\n",
    "    - transaction_on (str or List[str]): Key(s) from the transaction table to join on.\n",
    "    - customer_filters (dict): Filters for get_customers if no cust DataFrame is passed.\n",
    "    - transaction_filters (dict): Filters for get_transactions if no tran DataFrame is passed.\n",
    "    - cust (pd.DataFrame): Optional. Pre-filtered customer DataFrame.\n",
    "    - tran (pd.DataFrame): Optional. Pre-filtered transaction DataFrame.\n",
    "    - select_columns (str or List[str], optional): Columns to include in the final result.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Joined DataFrame of customers and transactions.\n",
    "    \"\"\"\n",
    "\n",
    "    customers_df = cust if cust is not None else get_customers(**(customer_filters or {}))\n",
    "    transactions_df = tran if tran is not None else get_transactions(**(transaction_filters or {}))\n",
    "\n",
    "    left_keys = [customer_on] if isinstance(customer_on, str) else customer_on\n",
    "    right_keys = [transaction_on] if isinstance(transaction_on, str) else transaction_on\n",
    "\n",
    "    merged = pd.merge(\n",
    "        customers_df,\n",
    "        transactions_df,\n",
    "        how=join_type.lower(),\n",
    "        left_on=left_keys,\n",
    "        right_on=right_keys,\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "\n",
    "    # Drop duplicate join columns from transactions\n",
    "    for rk in right_keys:\n",
    "        dup_col = f\"{rk}_dup\"\n",
    "        if dup_col in merged.columns:\n",
    "            merged.drop(columns=[dup_col], inplace=True)\n",
    "\n",
    "    # Select only specified columns if requested\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, str):\n",
    "            select_columns = [select_columns]\n",
    "        merged = merged[select_columns]\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ab543141-8edb-4297-8fd5-c6cb55be1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_join_acc_tran(\n",
    "    join_type: str = \"left\",\n",
    "    account_on: Union[str, List[str]] = \"account_no\",\n",
    "    transaction_on: Union[str, List[str]] = \"account_no\",\n",
    "    account_filters: Optional[dict] = None,\n",
    "    transaction_filters: Optional[dict] = None,\n",
    "    acc: Optional[pd.DataFrame] = None,\n",
    "    tran: Optional[pd.DataFrame] = None,\n",
    "    select_columns: Union[str, List[str], None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins account and transaction data on specified keys.\n",
    "\n",
    "    Parameters:\n",
    "    - join_type (str): Type of join ('left', 'inner', etc.). Default is 'left'.\n",
    "    - account_on (str or List[str]): Key(s) from the account table.\n",
    "    - transaction_on (str or List[str]): Key(s) from the transaction table.\n",
    "    - account_filters (dict): Filters to apply on get_accounts() if acc not provided.\n",
    "    - transaction_filters (dict): Filters to apply on get_transactions() if tran not provided.\n",
    "    - acc (pd.DataFrame): Optional. Pre-filtered account DataFrame.\n",
    "    - tran (pd.DataFrame): Optional. Pre-filtered transaction DataFrame.\n",
    "    - select_columns (str or List[str], optional): Subset of columns to return.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Joined account and transaction data.\n",
    "    \"\"\"\n",
    "\n",
    "    accounts_df = acc if acc is not None else get_accounts(**(account_filters or {}))\n",
    "    transactions_df = tran if tran is not None else get_transactions(**(transaction_filters or {}))\n",
    "\n",
    "    left_keys = [account_on] if isinstance(account_on, str) else account_on\n",
    "    right_keys = [transaction_on] if isinstance(transaction_on, str) else transaction_on\n",
    "\n",
    "    merged = pd.merge(\n",
    "        accounts_df,\n",
    "        transactions_df,\n",
    "        how=join_type.lower(),\n",
    "        left_on=left_keys,\n",
    "        right_on=right_keys,\n",
    "        suffixes=('', '_dup')\n",
    "    )\n",
    "\n",
    "    for rk in right_keys:\n",
    "        dup_col = f\"{rk}_dup\"\n",
    "        if dup_col in merged.columns:\n",
    "            merged.drop(columns=[dup_col], inplace=True)\n",
    "\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, str):\n",
    "            select_columns = [select_columns]\n",
    "        merged = merged[select_columns]\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f6eed-e1e3-4089-9dcc-99398b7352de",
   "metadata": {},
   "source": [
    "# LEVEL 3: Super Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2ee0dbb3-5205-4c73-887c-0f653eb436a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_join_cust_acc_tran(\n",
    "    join_type: str = \"left\",\n",
    "    customer_key: Union[str, List[str]] = \"customer_id\",\n",
    "    account_key: Union[str, List[str]] = \"account_no\",\n",
    "    transaction_key: Union[str, List[str]] = \"transaction_id\",\n",
    "    cust: Optional[pd.DataFrame] = None,\n",
    "    acc: Optional[pd.DataFrame] = None,\n",
    "    tran: Optional[pd.DataFrame] = None,\n",
    "    cust_acc_df: Optional[pd.DataFrame] = None,\n",
    "    cust_tran_df: Optional[pd.DataFrame] = None,\n",
    "    acc_tran_df: Optional[pd.DataFrame] = None,\n",
    "    select_columns: Union[str, List[str], None] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins customer-account, customer-transaction, and account-transaction data \n",
    "    into a unified DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - join_type (str): Type of join to use (default='left').\n",
    "    - customer_key (str or list of str): Keys to join on for customer joins.\n",
    "    - account_key (str or list of str): Keys to join on for account joins.\n",
    "    - transaction_key (str or list of str): Keys to join on for transaction joins.\n",
    "    - cust, acc, tran (pd.DataFrame): Optional pre-fetched raw DataFrames.\n",
    "    - cust_acc_df, cust_tran_df, acc_tran_df (pd.DataFrame): Optional pre-joined DataFrames.\n",
    "    - select_columns (str or List[str], optional): If specified, returns only selected columns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Fully merged DataFrame of customers, accounts, and transactions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fallback to default functions if not provided\n",
    "    if cust_acc_df is None:\n",
    "        cust_acc_df = get_cust_acc(cust=cust, acc=acc)\n",
    "    if cust_tran_df is None:\n",
    "        cust_tran_df = get_cust_tran(cust=cust, tran=tran)\n",
    "    if acc_tran_df is None:\n",
    "        acc_tran_df = get_acc_tran(acc=acc, tran=tran)\n",
    "\n",
    "    # Normalize join keys to lists\n",
    "    customer_keys = [customer_key] if isinstance(customer_key, str) else customer_key\n",
    "    account_keys = [account_key] if isinstance(account_key, str) else account_key\n",
    "    transaction_keys = [transaction_key] if isinstance(transaction_key, str) else transaction_key\n",
    "\n",
    "    # Merge customer-account with customer-transaction on customer keys\n",
    "    cust_merge = pd.merge(\n",
    "        cust_acc_df,\n",
    "        cust_tran_df,\n",
    "        how=join_type,\n",
    "        on=customer_keys,\n",
    "        suffixes=('', '_cust_tran')\n",
    "    )\n",
    "\n",
    "    # Merge with account-transaction on account keys\n",
    "    final_merge = pd.merge(\n",
    "        cust_merge,\n",
    "        acc_tran_df,\n",
    "        how=join_type,\n",
    "        on=account_keys,\n",
    "        suffixes=('', '_acc_tran')\n",
    "    )\n",
    "\n",
    "    # Drop duplicate transaction join keys if present\n",
    "    for key in transaction_keys:\n",
    "        for suffix in ['_cust_tran', '_acc_tran']:\n",
    "            dup_col = f\"{key}{suffix}\"\n",
    "            if dup_col in final_merge.columns:\n",
    "                final_merge.drop(columns=[dup_col], inplace=True)\n",
    "\n",
    "    # Return only selected columns if provided\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, str):\n",
    "            select_columns = [select_columns]\n",
    "        final_merge = final_merge[select_columns]\n",
    "\n",
    "    return final_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b8322f2-83bc-4ac7-b507-7c8d3a252eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes in website make it such that if the user dont want to use custome code he/she can directly add the \n",
    "# rules by using the above only and if wants to use the custom code only he/she can write it but\n",
    "# dont ask the user to write both for the rules to be executed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cf7bb4d1-2bf9-41cd-9078-8ac89b27c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how to make it platform independent like A--->B--->C\n",
    "#                                                A<---B<---C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cae7673e-3e4c-4654-b70b-d0fd12b03b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A : our code of everything in pandas\n",
    "# B : Connect it with FAST API\n",
    "# C : Say the client is using Java and he wants to access the Data Frame "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4614df-4166-418d-a034-338f8cc311a5",
   "metadata": {},
   "source": [
    "# Single Functions for each level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c45eba72-dded-4724-a071-56585c13c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_data(\n",
    "    table_name: str,\n",
    "    filters: Dict[str, Any] = None,\n",
    "    date_fields: List[str] = None,\n",
    "    min_max_fields: Dict[str, Dict[str, Union[str, datetime, float]]] = None,\n",
    "    select_columns: Union[str, List[str], None] = None,\n",
    "    df: Optional[pd.DataFrame] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generalized function to fetch records from any table or passed DataFrame (customer, accounts, transactions).\n",
    "    \n",
    "    Parameters:\n",
    "    - table_name: Name of the table (ignored if df is provided)\n",
    "    - filters: Dictionary of exact values or lists to filter (e.g., {'name': ['Alice', 'Bob'], 'city': 'Delhi'})\n",
    "    - date_fields: List of fields that are dates or datetimes (used for parsing)\n",
    "    - min_max_fields: Dict with min/max filters. Format:\n",
    "        {\n",
    "            'update_date': {'min': '2024-01-01', 'max': '2024-12-31'},\n",
    "            'amount': {'min': 1000, 'max': 100000}\n",
    "        }\n",
    "    - select_columns: Comma string or list of columns to return\n",
    "    - df: Optional. If provided, will filter on this DataFrame instead of querying the DB\n",
    "    \n",
    "    Returns:\n",
    "    - Filtered DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = filters or {}\n",
    "    date_fields = date_fields or []\n",
    "    min_max_fields = min_max_fields or {}\n",
    "\n",
    "    def parse_value(val, is_date=False):\n",
    "        if is_date:\n",
    "            if isinstance(val, str):\n",
    "                try:\n",
    "                    return datetime.strptime(val, '%Y-%m-%d')\n",
    "                except:\n",
    "                    return datetime.strptime(val, '%Y-%m-%d %H:%M:%S')\n",
    "        return val\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # If df is provided, apply filtering directly\n",
    "    # --------------------------------------------\n",
    "    if df is not None:\n",
    "        df_copy = df.copy()\n",
    "\n",
    "        # Apply filters\n",
    "        for field, value in filters.items():\n",
    "            is_date = field in date_fields\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                df_copy = df_copy[df_copy[field].isin([parse_value(v, is_date) for v in value])]\n",
    "            else:\n",
    "                df_copy = df_copy[df_copy[field] == parse_value(value, is_date)]\n",
    "\n",
    "        # Apply min/max filters\n",
    "        for field, bounds in min_max_fields.items():\n",
    "            if 'min' in bounds:\n",
    "                df_copy = df_copy[df_copy[field] >= parse_value(bounds['min'], field in date_fields)]\n",
    "            if 'max' in bounds:\n",
    "                df_copy = df_copy[df_copy[field] <= parse_value(bounds['max'], field in date_fields)]\n",
    "\n",
    "        # Select columns\n",
    "        if select_columns:\n",
    "            if isinstance(select_columns, str):\n",
    "                select_columns = [select_columns]\n",
    "            df_copy = df_copy[select_columns]\n",
    "\n",
    "        return df_copy\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Else: fallback to database query using psycopg2/sql\n",
    "    # -----------------------------------------------------\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = get_db_engine()\n",
    "\n",
    "    if isinstance(select_columns, list):\n",
    "        column_str = \", \".join(select_columns)\n",
    "    elif isinstance(select_columns, str):\n",
    "        column_str = select_columns\n",
    "    else:\n",
    "        column_str = \"*\"\n",
    "\n",
    "    query = f\"SELECT {column_str} FROM {table_name} WHERE 1=1\"\n",
    "    params = {}\n",
    "    param_counter = 0\n",
    "\n",
    "    for field, value in filters.items():\n",
    "        is_date = field in date_fields\n",
    "        prefix = f\"{field}_{param_counter}\"\n",
    "        param_counter += 1\n",
    "\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            clause_parts = []\n",
    "            for i, val in enumerate(value):\n",
    "                pname = f\"{prefix}_{i}\"\n",
    "                clause_parts.append(f\"{field} = %({pname})s\")\n",
    "                params[pname] = parse_value(val, is_date)\n",
    "            query += \" AND (\" + \" OR \".join(clause_parts) + \")\"\n",
    "        else:\n",
    "            pname = f\"{prefix}\"\n",
    "            params[pname] = parse_value(value, is_date)\n",
    "            query += f\" AND {field} = %({pname})s\"\n",
    "\n",
    "    for field, bounds in min_max_fields.items():\n",
    "        if 'min' in bounds:\n",
    "            query += f\" AND {field} >= %(min_{field})s\"\n",
    "            params[f\"min_{field}\"] = parse_value(bounds['min'], field in date_fields)\n",
    "        if 'max' in bounds:\n",
    "            query += f\" AND {field} <= %(max_{field})s\"\n",
    "            params[f\"max_{field}\"] = parse_value(bounds['max'], field in date_fields)\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            if params:\n",
    "                with conn.connection.cursor() as cursor:\n",
    "                    cursor.execute(query, params)\n",
    "                    columns = [desc[0] for desc in cursor.description]\n",
    "                    rows = cursor.fetchall()\n",
    "                    return pd.DataFrame(rows, columns=columns)\n",
    "            else:\n",
    "                return pd.read_sql(query, conn)\n",
    "    finally:\n",
    "        engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fe5f91b7-9a01-4447-8085-3380c43e9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def universal_data_join(\n",
    "    tables_to_join: List[str],\n",
    "    join_type: str = \"left\",\n",
    "    join_keys: Dict[str, str] = None,\n",
    "    filters: Dict[str, dict] = None,\n",
    "    select_columns: Union[List[str], str, None] = None,\n",
    "    preloaded_data: Dict[str, pd.DataFrame] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dynamically joins selected tables (customer, account, transaction) based on input order.\n",
    "\n",
    "    Parameters:\n",
    "    - tables_to_join: List of table names to join, in order (e.g. [\"customer\", \"account\"])\n",
    "    - join_type: Join type ('left', 'inner', etc.)\n",
    "    - join_keys: Dict of table_name → join column in that table\n",
    "    - filters: Optional dict of filters per table\n",
    "    - preloaded_data: Optional dict of DataFrames per table\n",
    "    - select_columns: Optional final list of columns to return\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Final merged result\n",
    "    \"\"\"\n",
    "    assert len(tables_to_join) >= 2, \"You must select at least two tables to join.\"\n",
    "    assert join_keys is not None, \"You must specify join keys for each table.\"\n",
    "\n",
    "    fetch_functions = {\n",
    "        \"customer\": get_customers,\n",
    "        \"account\": get_accounts,\n",
    "        \"transaction\": get_transactions\n",
    "    }\n",
    "\n",
    "    dataframes = {}\n",
    "\n",
    "    for table in tables_to_join:\n",
    "        if preloaded_data and table in preloaded_data:\n",
    "            dataframes[table] = preloaded_data[table]\n",
    "        else:\n",
    "            if table not in fetch_functions:\n",
    "                raise ValueError(f\"No fetch function available for table '{table}'\")\n",
    "            dataframes[table] = fetch_functions[table](**(filters.get(table, {}) if filters else {}))\n",
    "\n",
    "    # Start joining\n",
    "    merged = dataframes[tables_to_join[0]]\n",
    "    \n",
    "    for i in range(1, len(tables_to_join)):\n",
    "        left_table = tables_to_join[i - 1]\n",
    "        right_table = tables_to_join[i]\n",
    "        left_key = join_keys[left_table]\n",
    "        right_key = join_keys[right_table]\n",
    "\n",
    "        merged = pd.merge(\n",
    "            merged,\n",
    "            dataframes[right_table],\n",
    "            how=join_type,\n",
    "            left_on=left_key,\n",
    "            right_on=right_key,\n",
    "            suffixes=('', f'_{right_table}')\n",
    "        )\n",
    "\n",
    "    if select_columns:\n",
    "        if isinstance(select_columns, str):\n",
    "            select_columns = [select_columns]\n",
    "        merged = merged[select_columns]\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "777b19fa-9ba1-4a8d-9080-db2af8bacbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>account_type</th>\n",
       "      <th>account_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rohan Mehta</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vivek Choudhary</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Savings</td>\n",
       "      <td>Suspended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neeta Sharma</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    city account_type account_status\n",
       "0      Rohan Mehta  Jaipur      Savings         Active\n",
       "1  Vivek Choudhary  Jaipur      Savings      Suspended\n",
       "2     Neeta Sharma  Jaipur          NaN            NaN\n",
       "3      Amit Sharma  Jaipur          NaN            NaN"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universal_data_join(tables_to_join=[\"customer\",\"account\"],\n",
    "                   join_keys={\"customer\":\"customer_id\",\"account\":\"customer_id\"},\n",
    "                    filters={\"customer\":{\"city\":\"Jaipur\"},\n",
    "                            \"account\":{\"account_type\":\"Savings\"}\n",
    "                            },\n",
    "                    select_columns=[\"name\",\"city\",\"account_type\",\"account_status\"]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ae8ab-9451-4761-9bf5-81795cf44449",
   "metadata": {},
   "source": [
    "# Making The Above Two Function as a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fc8f19b3-b292-4566-ac46-214d29badd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Table names are:\n",
    "#1.customer\n",
    "#2.accounts\n",
    "#3.transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f0a2ae53-ce68-427c-8f82-450c374359d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two function into a class such that it can be accesed anywhere\n",
    "class DataJoiner:\n",
    "    def __init__(self, db_engine_func):\n",
    "        self.get_db_engine = db_engine_func  # A function that returns a DB engine or simply it connects with the database engine\n",
    "\n",
    "    def get_table_data(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        filters: Dict[str, Any] = None,\n",
    "        date_fields: List[str] = None,\n",
    "        min_max_fields: Dict[str, Dict[str, Union[str, datetime, float]]] = None,\n",
    "        select_columns: Union[str, List[str], None] = None,\n",
    "        df: Optional[pd.DataFrame] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generalized function to fetch records from any table or passed DataFrame (customer, accounts, transactions).\n",
    "        \n",
    "        Parameters:\n",
    "        - table_name: Name of the table (ignored if df is provided)\n",
    "        - filters: Dictionary of exact values or lists to filter\n",
    "        - date_fields: List of fields that are dates or datetimes\n",
    "        - min_max_fields: Dict with min/max filters\n",
    "        - select_columns: Columns to return\n",
    "        - df: Optional. If provided, filters on this DataFrame\n",
    "        \n",
    "        Returns:\n",
    "        - pd.DataFrame: Filtered DataFrame\n",
    "        \"\"\"\n",
    "        filters = filters or {}\n",
    "        date_fields = date_fields or []\n",
    "        min_max_fields = min_max_fields or {}\n",
    "\n",
    "        def parse_value(val, is_date=False):\n",
    "            if is_date and isinstance(val, str):\n",
    "                try:\n",
    "                    return datetime.strptime(val, '%Y-%m-%d')\n",
    "                except:\n",
    "                    return datetime.strptime(val, '%Y-%m-%d %H:%M:%S')\n",
    "            return val\n",
    "\n",
    "        if df is not None:\n",
    "            df_copy = df.copy()\n",
    "\n",
    "            for field, value in filters.items():\n",
    "                is_date = field in date_fields\n",
    "                if isinstance(value, (list, tuple)):\n",
    "                    df_copy = df_copy[df_copy[field].isin([parse_value(v, is_date) for v in value])]\n",
    "                else:\n",
    "                    df_copy = df_copy[df_copy[field] == parse_value(value, is_date)]\n",
    "\n",
    "            for field, bounds in min_max_fields.items():\n",
    "                if 'min' in bounds:\n",
    "                    df_copy = df_copy[df_copy[field] >= parse_value(bounds['min'], field in date_fields)]\n",
    "                if 'max' in bounds:\n",
    "                    df_copy = df_copy[df_copy[field] <= parse_value(bounds['max'], field in date_fields)]\n",
    "\n",
    "            if select_columns:\n",
    "                if isinstance(select_columns, str):\n",
    "                    select_columns = [select_columns]\n",
    "                df_copy = df_copy[select_columns]\n",
    "\n",
    "            return df_copy\n",
    "\n",
    "        # DB fetching\n",
    "        engine = self.get_db_engine()\n",
    "        column_str = \", \".join(select_columns) if isinstance(select_columns, list) else (select_columns or \"*\")\n",
    "        query = f\"SELECT {column_str} FROM {table_name} WHERE 1=1\"\n",
    "        params = {}\n",
    "        param_counter = 0\n",
    "\n",
    "        for field, value in filters.items():\n",
    "            is_date = field in date_fields\n",
    "            prefix = f\"{field}_{param_counter}\"\n",
    "            param_counter += 1\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                parts = []\n",
    "                for i, val in enumerate(value):\n",
    "                    pname = f\"{prefix}_{i}\"\n",
    "                    parts.append(f\"{field} = %({pname})s\")\n",
    "                    params[pname] = parse_value(val, is_date)\n",
    "                query += \" AND (\" + \" OR \".join(parts) + \")\"\n",
    "            else:\n",
    "                pname = prefix\n",
    "                query += f\" AND {field} = %({pname})s\"\n",
    "                params[pname] = parse_value(value, is_date)\n",
    "\n",
    "        for field, bounds in min_max_fields.items():\n",
    "            if 'min' in bounds:\n",
    "                query += f\" AND {field} >= %(min_{field})s\"\n",
    "                params[f\"min_{field}\"] = parse_value(bounds['min'], field in date_fields)\n",
    "            if 'max' in bounds:\n",
    "                query += f\" AND {field} <= %(max_{field})s\"\n",
    "                params[f\"max_{field}\"] = parse_value(bounds['max'], field in date_fields)\n",
    "\n",
    "        with engine.connect() as conn:\n",
    "            if params:\n",
    "                with conn.connection.cursor() as cursor:\n",
    "                    cursor.execute(query, params)\n",
    "                    rows = cursor.fetchall()\n",
    "                    cols = [desc[0] for desc in cursor.description]\n",
    "                    return pd.DataFrame(rows, columns=cols)\n",
    "            else:\n",
    "                return pd.read_sql(query, conn)\n",
    "\n",
    "    def universal_data_join(\n",
    "        self,\n",
    "        tables_to_join: List[str],\n",
    "        join_type: str = \"left\",\n",
    "        join_keys: Dict[str, str] = None,\n",
    "        filters: Dict[str, dict] = None,\n",
    "        select_columns: Union[List[str], str, None] = None,\n",
    "        preloaded_data: Dict[str, pd.DataFrame] = None,\n",
    "        date_fields: Dict[str, List[str]] = None,\n",
    "        min_max_fields: Dict[str, Dict[str, Dict[str, Union[str, float]]]] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Dynamically joins selected tables (customer, account, transaction) based on input order.\n",
    "\n",
    "        Parameters:\n",
    "        - tables_to_join: List of table names to join, in order\n",
    "        - join_type: Type of join\n",
    "        - join_keys: Dict of table_name → join column in that table\n",
    "        - filters: Optional filters per table\n",
    "        - preloaded_data: Optional dict of DataFrames per table\n",
    "        - select_columns: Optional list of columns to return\n",
    "        - date_fields: Dict of table_name → date columns\n",
    "        - min_max_fields: Dict of table_name → field → {min, max}\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: Final merged DataFrame\n",
    "        \"\"\"\n",
    "        assert len(tables_to_join) >= 2, \"You must join at least two tables.\"\n",
    "        assert join_keys is not None, \"You must specify join keys for each table.\"\n",
    "\n",
    "        dataframes = {}\n",
    "\n",
    "        for table in tables_to_join:\n",
    "            if preloaded_data and table in preloaded_data:\n",
    "                df = preloaded_data[table]\n",
    "            else:\n",
    "                df = self.get_table_data(\n",
    "                    table_name=table,\n",
    "                    filters=(filters or {}).get(table, {}),\n",
    "                    date_fields=(date_fields or {}).get(table, []),\n",
    "                    min_max_fields=(min_max_fields or {}).get(table, {}),\n",
    "                    select_columns=None\n",
    "                )\n",
    "            dataframes[table] = df\n",
    "\n",
    "        merged = dataframes[tables_to_join[0]]\n",
    "\n",
    "        for i in range(1, len(tables_to_join)):\n",
    "            left_table = tables_to_join[i - 1]\n",
    "            right_table = tables_to_join[i]\n",
    "            left_key = join_keys[left_table]\n",
    "            right_key = join_keys[right_table]\n",
    "\n",
    "            merged = pd.merge(\n",
    "                merged,\n",
    "                dataframes[right_table],\n",
    "                how=join_type,\n",
    "                left_on=left_key,\n",
    "                right_on=right_key,\n",
    "                suffixes=('', f'_{right_table}')\n",
    "            )\n",
    "\n",
    "        if select_columns:\n",
    "            if isinstance(select_columns, str):\n",
    "                select_columns = [select_columns]\n",
    "            merged = merged[select_columns]\n",
    "\n",
    "        return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f52c78-3a30-4884-b393-267192a5dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_data_join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
